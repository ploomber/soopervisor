{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b02ab81-29a8-4830-b15c-9950ccdc8934",
   "metadata": {},
   "source": [
    "# From notebook to Kubernetes pipeline\n",
    "\n",
    "![](assets/nb.png)\n",
    "\n",
    "This tutorial will show you how to automatically convert a Jupyter notebook into a Kubernetes pipeline.\n",
    "\n",
    "Let's download a sample notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139e29c4-4bcc-4fe4-a922-78712ae72254",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# conda activate {env} doesn't work well here\n",
    "# so we manually modify the path\n",
    "PATH=$CONDA_PREFIX/envs/soopervisor/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e39561-9d9b-4c55-a1b4-953f47bffa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir pipeline\n",
    "cd pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165a42ca-df19-43e9-a84c-990d71339e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5782  100  5782    0     0  23892      0 --:--:-- --:--:-- --:--:-- 23794\n"
     ]
    }
   ],
   "source": [
    "curl -O https://raw.githubusercontent.com/ploomber/soorgeon/main/examples/machine-learning/nb.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f115378-bddb-4907-9947-c2c3612ae607",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The sample notebook is a typical Machine\n",
    "Learning pipeline, you can see it\n",
    "[here](https://github.com/ploomber/soorgeon/blob/main/examples/machine-learning/nb.ipynb)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b0a8f-be33-4f34-b70e-15ec1af6b1c2",
   "metadata": {},
   "source": [
    "## Automatic refactoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9894fec-8f3f-41d8-ba55-c520df476051",
   "metadata": {},
   "source": [
    "Let's now use [soorgeon](https://github.com/ploomber/soorgeon) to refactor the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0e8b98-7bfc-4b37-81fc-beedd062a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added README.md\n",
      "\u001b[32mFinished refactoring 'nb.ipynb', use Ploomber to continue.\u001b[0m\n",
      "\n",
      "Install dependencies (this will install ploomber):\n",
      "    $ pip install -r requirements.txt\n",
      "\n",
      "List tasks:\n",
      "    $ ploomber status\n",
      "\n",
      "Execute pipeline:\n",
      "    $ ploomber build\n",
      "\n",
      "Plot pipeline:\n",
      "    $ ploomber plot\n",
      "\n",
      "* Documentation: https://docs.ploomber.io\n",
      "* Jupyter integration: https://ploomber.io/s/jupyter\n",
      "* Other editors: https://ploomber.io/s/editors\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install soorgeon --quiet\n",
    "soorgeon refactor nb.ipynb -p /mnt/shared-folder -d parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5f766-71df-4ecf-befa-2d7945295628",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Soorgeon uses static analysis to split notebooks into\n",
    "several files, the output is a [Ploomber](https://github.com/ploomber/ploomber)\n",
    "pipeline that then we can export to Kubernetes.\n",
    "\n",
    "The `-p` tells Soorgeon that it should store all the pipeline\n",
    "outputs in a `/mnt/shared-folder` directory, and the `-d`\n",
    "option states we should use `.parquet` files for the outputs.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0ac78-c7ca-4085-976e-168f3ed3ecca",
   "metadata": {},
   "source": [
    "We now configure the Argo workflows backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b87e099-af19-4626-9d70-425b0e5b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soopervisor add requires a requirements.lock.txt file\n",
    "cp requirements.txt requirements.lock.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b98cdd-b6d0-410a-a1b6-1e74b4e303bd",
   "metadata": {},
   "source": [
    "## Configuring Argo Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d07a209-1aa2-4877-a451-7a4f77fe29a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m================================= Loading DAG ==================================\u001b[0m\n",
      "No pipeline.training.yaml found, looking for pipeline.yaml instead\n",
      "Found /Users/Edu/dev/soopervisor/kind/doc/pipeline/pipeline.yaml. Loading...\n",
      "\u001b[34m== Adding /Users/Edu/dev/soopervisor/kind/doc/pipeline/training/Dockerfile... ==\u001b[0m\n",
      "\u001b[32m===================================== Done =====================================\u001b[0m\n",
      "Environment added, to export it:\n",
      "\t $ soopervisor export training\n",
      "To force execution of all tasks:\n",
      "\t $ soopervisor export training --mode force\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# add the taget environment\n",
    "soopervisor add training --backend argo-workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c632c6-9d0f-4ae2-ad36-e8703c7d93de",
   "metadata": {},
   "source": [
    "Soopervisor uses a `soopervisor.yaml` to configure your project, we'll download a pre-configured one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644a275f-f109-49a2-b6a2-8adf5b2501f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   152  100   152    0     0    569      0 --:--:-- --:--:-- --:--:--   567\n"
     ]
    }
   ],
   "source": [
    "curl https://raw.githubusercontent.com/ploomber/soopervisor/master/tutorials/workflow/soopervisor-workflow.yaml -o soopervisor.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1781fd40-8e39-4b95-b5f3-08e466a74dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "  backend: argo-workflows\n",
      "  repository: null\n",
      "  mounted_volumes:\n",
      "    - name: shared-folder\n",
      "      spec:\n",
      "        hostPath:\n",
      "          path: /host\n"
     ]
    }
   ],
   "source": [
    "cat soopervisor.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be86d4b-c911-4a51-ba0b-3807eb2d2b43",
   "metadata": {},
   "source": [
    "## Exporting Argo YAML Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521ced3-39a8-4619-8ac6-dbcb2583c31e",
   "metadata": {},
   "source": [
    "The `soopervisor export` command will create the Docker image and the Argo YAML spec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a6f74-9cca-4119-9752-e206cb9895da",
   "metadata": {},
   "outputs": [],
   "source": [
    "soopervisor export training --skip-tests --ignore-git --mode force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d204b-6fdd-48e4-9cd4-56fcdf743f2f",
   "metadata": {},
   "source": [
    "Here's the generated Argo YAML spec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc48b184-ccc2-4bd9-964e-11c237a01192",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: argoproj.io/v1alpha1\n",
      "kind: Workflow\n",
      "metadata:\n",
      "  generateName: pipeline-\n",
      "spec:\n",
      "  entrypoint: dag\n",
      "  templates:\n",
      "  - inputs:\n",
      "      parameters:\n",
      "      - name: task_name\n",
      "    name: run-task\n",
      "    script:\n",
      "      command:\n",
      "      - bash\n",
      "      image: pipeline:latest-default\n",
      "      imagePullPolicy: Never\n",
      "      source: |-\n",
      "        ploomber task {{inputs.parameters.task_name}} --entry-point pipeline.yaml --force\n",
      "      volumeMounts:\n",
      "      - mountPath: /mnt/shared-folder\n",
      "        name: shared-folder\n",
      "        subPath: ''\n",
      "      workingDir: null\n",
      "  - dag:\n",
      "      tasks:\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: task_name\n",
      "            value: load\n",
      "        dependencies: []\n",
      "        name: load\n",
      "        template: run-task\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: task_name\n",
      "            value: clean\n",
      "        dependencies:\n",
      "        - load\n",
      "        name: clean\n",
      "        template: run-task\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: task_name\n",
      "            value: train-test-split\n",
      "        dependencies:\n",
      "        - clean\n",
      "        name: train-test-split\n",
      "        template: run-task\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: task_name\n",
      "            value: linear-regression\n",
      "        dependencies:\n",
      "        - train-test-split\n",
      "        name: linear-regression\n",
      "        template: run-task\n",
      "      - arguments:\n",
      "          parameters:\n",
      "          - name: task_name\n",
      "            value: random-forest-regressor\n",
      "        dependencies:\n",
      "        - train-test-split\n",
      "        name: random-forest-regressor\n",
      "        template: run-task\n",
      "    name: dag\n",
      "  volumes:\n",
      "  - hostPath:\n",
      "      path: /host\n",
      "    name: shared-folder\n"
     ]
    }
   ],
   "source": [
    "cat training/argo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a860d3-00a8-4c40-bb7b-6212259d76d5",
   "metadata": {},
   "source": [
    "## Running on Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c11d4b8-d30d-4d27-8209-561ac771d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting cluster \"kind\" ...\n"
     ]
    }
   ],
   "source": [
    "kind delete cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2e4866-2af6-4294-a248-1843803e8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating cluster \"kind\" ...\n",
      " \u001b[32m✓\u001b[0m Ensuring node image (kindest/node:v1.24.0) 🖼7l\n",
      " \u001b[32m✓\u001b[0m Preparing nodes 📦 7l\n",
      " \u001b[32m✓\u001b[0m Writing configuration 📜7l\n",
      " \u001b[32m✓\u001b[0m Starting control-plane 🕹️7l\n",
      " \u001b[32m✓\u001b[0m Installing CNI 🔌7l\n",
      " \u001b[32m✓\u001b[0m Installing StorageClass 💾7l\n",
      "Set kubectl context to \"kind-kind\"\n",
      "You can now use your cluster with:\n",
      "\n",
      "kubectl cluster-info --context kind-kind\n",
      "\n",
      "Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂\n",
      "You have new mail in /var/mail/Edu\n"
     ]
    }
   ],
   "source": [
    "kind create cluster --config ../kind-config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48aa692d-604c-4ab6-8af0-c93e7ce813f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: kind.x-k8s.io/v1alpha4\n",
      "kind: Cluster\n",
      "nodes:\n",
      "  - role: control-plane\n",
      "    extraMounts:\n",
      "      - hostPath: outputs\n",
      "        containerPath: /host\n"
     ]
    }
   ],
   "source": [
    "cat ../kind-config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5984a2-dcc0-4d70-b414-fb3fd7aaa510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 STATUS   ROLES           AGE   VERSION\n",
      "kind-control-plane   Ready    control-plane   43s   v1.24.0\n"
     ]
    }
   ],
   "source": [
    "kubectl get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "166aa541-c335-4808-9ad5-b6d9621381f1",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/argo created\n",
      "customresourcedefinition.apiextensions.k8s.io/clusterworkflowtemplates.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/cronworkflows.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workfloweventbindings.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtaskresults.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtasksets.argoproj.io created\n",
      "customresourcedefinition.apiextensions.k8s.io/workflowtemplates.argoproj.io created\n",
      "serviceaccount/argo created\n",
      "serviceaccount/argo-server created\n",
      "role.rbac.authorization.k8s.io/argo-role created\n",
      "clusterrole.rbac.authorization.k8s.io/argo-aggregate-to-admin created\n",
      "clusterrole.rbac.authorization.k8s.io/argo-aggregate-to-edit created\n",
      "clusterrole.rbac.authorization.k8s.io/argo-aggregate-to-view created\n",
      "clusterrole.rbac.authorization.k8s.io/argo-cluster-role created\n",
      "clusterrole.rbac.authorization.k8s.io/argo-server-cluster-role created\n",
      "rolebinding.rbac.authorization.k8s.io/argo-binding created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/argo-binding created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/argo-server-binding created\n",
      "configmap/workflow-controller-configmap created\n",
      "service/argo-server created\n",
      "service/workflow-controller-metrics created\n",
      "priorityclass.scheduling.k8s.io/workflow-controller created\n",
      "deployment.apps/argo-server created\n",
      "deployment.apps/workflow-controller created\n"
     ]
    }
   ],
   "source": [
    "kubectl create namespace argo\n",
    "kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/download/v3.3.9/install.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8c88f7-40fe-4cf1-a7ae-03ce19647186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/argo-server patched\n"
     ]
    }
   ],
   "source": [
    "kubectl patch deployment \\\n",
    "  argo-server \\\n",
    "  --namespace argo \\\n",
    "  --type='json' \\\n",
    "  -p='[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/args\", \"value\": [\n",
    "  \"server\",\n",
    "  \"--auth-mode=server\"\n",
    "]}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf419d47-2d58-4ace-a1b1-aa38bbedd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85feac7-32b0-4cc9-9863-48fc80d10bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                   READY   STATUS    RESTARTS   AGE\n",
      "argo-server-57cf87c886-54hgn           0/1     Running   0          9s\n",
      "argo-server-65566599f8-7zrz8           0/1     Running   0          12s\n",
      "workflow-controller-77c44779bf-vl65l   1/1     Running   0          12s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods -n argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfcd42ca-89d5-4305-aa12-d58d5d3e44bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: \"pipeline:latest-default\" with ID \"sha256:192bb0cda7e554ee28ed80abded89a46d53cfd3f4a60e0bd447ddffad18407c4\" not yet present on node \"kind-control-plane\", loading...\n",
      "You have new mail in /var/mail/Edu\n"
     ]
    }
   ],
   "source": [
    "kind load docker-image pipeline:latest-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5b8d7af-7331-434e-bb10-2cdc6ea03210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:                pipeline-dw79l\n",
      "Namespace:           argo\n",
      "ServiceAccount:      default\n",
      "Status:              Pending\n",
      "Created:             Sun Aug 28 01:59:18 -0500 (now)\n",
      "Progress:            \n"
     ]
    }
   ],
   "source": [
    "argo submit -n argo training/argo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3794e-dd53-4390-846b-fccee6bb4c2d",
   "metadata": {},
   "source": [
    "```{note}\n",
    "To access Argo's UI, open a terminal and execute:\n",
    "\n",
    "`kubectl -n argo port-forward deployment/argo-server 2746:2746`\n",
    "\n",
    "Then, open: https://localhost:2746/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a82e965-a823-474b-a536-0725c6ade379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@latest Succeeded at 2022-08-28 02:01:35 -0500 CDT\n",
      "You have new mail in /var/mail/Edu\n"
     ]
    }
   ],
   "source": [
    "argo wait @latest -n argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5aadd675-185c-4176-b0ee-6d7737f5e589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:                pipeline-dw79l\n",
      "Namespace:           argo\n",
      "ServiceAccount:      default\n",
      "Status:              Succeeded\n",
      "Conditions:          \n",
      " PodRunning          False\n",
      " Completed           True\n",
      "Created:             Sun Aug 28 01:59:18 -0500 (2 minutes ago)\n",
      "Started:             Sun Aug 28 01:59:18 -0500 (2 minutes ago)\n",
      "Finished:            Sun Aug 28 02:01:35 -0500 (now)\n",
      "Duration:            2 minutes 17 seconds\n",
      "Progress:            5/5\n",
      "ResourcesDuration:   3m1s*(1 cpu),3m1s*(100Mi memory)\n",
      "\n",
      "\u001b[39mSTEP\u001b[0m                          TEMPLATE  PODNAME                    DURATION  MESSAGE\n",
      " \u001b[32m✔\u001b[0m pipeline-dw79l             dag                                              \n",
      " ├─\u001b[32m✔\u001b[0m load                     run-task  pipeline-dw79l-3455339821  42s         \n",
      " ├─\u001b[32m✔\u001b[0m clean                    run-task  pipeline-dw79l-4113816922  21s         \n",
      " ├─\u001b[32m✔\u001b[0m train-test-split         run-task  pipeline-dw79l-112166065   15s         \n",
      " ├─\u001b[32m✔\u001b[0m linear-regression        run-task  pipeline-dw79l-4216685658  19s         \n",
      " └─\u001b[32m✔\u001b[0m random-forest-regressor  run-task  pipeline-dw79l-2688682065  24s         \n"
     ]
    }
   ],
   "source": [
    "argo get @latest -n argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeded9ff-2fb2-498e-a70a-b7e178fc0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean-df.parquet               train-test-split-X_test.pkl\n",
      "clean.ipynb                    train-test-split-X_train.pkl\n",
      "linear-regression.ipynb        train-test-split-y_test.pkl\n",
      "load-df.parquet                train-test-split-y_train.pkl\n",
      "load.ipynb                     train-test-split.ipynb\n",
      "random-forest-regressor.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls outputs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
